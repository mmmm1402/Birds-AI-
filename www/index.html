<!DOCTYPE HTML>
<html>
<head>
    <style>
    #button1 {
    border: solid 2px blue;
    border-radius: 10px;
    background-color: lightblue;
    padding: 20px;
    }
  </style>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta http-equiv="Content-Security-Policy" content="default-src * data: gap: content: https://ssl.gstatic.com; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval'">
    <script src="components/loader.js"></script>
    <link rel="stylesheet" href="components/loader.css">
    <link rel="stylesheet" href="css/style.css">
    <script>
        let aiSound = new Audio
        ("https://cdn.glitch.com/430eea81-64c4-42e3-8454-d278074c1aa8%2Fdecision29.mp3?v=1597194999835")

        let lat;
        let long;
        let altitude;
        let speed;
        let deviceSpeed;

        let geolocationSuccess = function(position) {
            lat.innerHTML = position.coords.latitude;
            long.innerHTML = position.coords.longitude;
            altitude.innerHTML = position.coords.altitude;
            speed.innerHTML = position.coords.speed;
            deviceSpeed = position.coords.speed;
        };

        let options = {
            enableHighAccuracy: true,
            timeout: 5000,
            maximumAge: 0
        };

        function init() {
            lat = document.getElementById("lat");
            long = document.getElementById("long");
            altitude = document.getElementById("altitude");
            speed = document.getElementById("speed");
            navigator.geolocation.watchPosition(geolocationSuccess, null, options);

            }
    </script>
    
</head>
<body onload= "init();">
        <dl>
        <dt>緯度:</dt><dd id="lat"></dd>
        <dt>経度:</dt><dd id="long"></dd>
        <dt>高さ:</dt><dd id="altitude"></dd>
        <dt>速度:</dt><dd id="speed"></dd>
        </dl>

        <div>Teachable Machine Image Model</div>

<button type="button"value="ボタン１" id="button1" onclick="tm_init()">Start</button>
<div id="webcam-container"></div>
<div id="label-container"></div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/bt1nvdje/";

    let model, webcam, labelContainer, letictions;


    // Load the image model and setup the webcam
    async function tm_init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(
            {
            facingMode: "environment"
            }
        ); // request access to the webcam      
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");

        for (let i = 0; i < maxPredictions; i++) { // and class labels
        labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
        }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ":" + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
            let hit = prediction[i].probability.toFixed(2);
            let Name2 = prediction[i].className
            checkSpeed();

            function checkSpeed() {
             window.requestAnimationFrame(checkSpeed);
             if (deviceSpeed >= 7){
                aiSound.play();
             }
              }
            //checkSpeed();

        //function checkSpeed() {
       //window.requestAnimationFrame(checkSpeed);
       //}
            
            if (Name2 == "安全確認してね"){
                if (hit >= 0.95){
                    //if (deviceSpeed <= 2){
                        aiSound.play();
                    //}
                }
            }
    }
            
        }
    
</script>  
	<br />
    <strong>BirdsAI ～ぴーちゃん～</strong><br>
    自転車危険予測アプリ
    </br>
</body>
</html>
